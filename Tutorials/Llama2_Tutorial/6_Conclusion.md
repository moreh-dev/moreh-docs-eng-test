---
icon: terminal
tags: [guide]
order: 40
---

# 6. Conclusion 

From this tutorial, we have seen how to fine-tune [Llama2 13B](https://huggingface.co/meta-llama/Llama-2-13b-hf) for text summarization on the MoAI Platform. Open-source LLMs like Llama can be utilized for various natural language processing tasks such as summarization, question answering, and more. With the MoAI Platform, you can easily configure the required number of GPUs without any code modifications. 

The availability of large language models like LLaMA 2, fine-tuning techniques, and the MoAI Platform makes it possible for anyone to develop powerful AI applications. So please start repeating the same process outlined here on your own data.

In case if you still have any questions regarding this tutorial feel free to ask Moreh.


## Learn More

- *[MoAI Platform의 자동병렬화 기능,  Advanced Parallelization (AP)](/Supported_Documents/)*
- [Mistral Fine-tuning](/Tutorials/Mistral_Tutorial/index.md)
- [GPT Fine-tuning](/Tutorials/GPT_Tutorial/index.md)
- [Baichuan2 Fine-tuning](/Tutorials/Baichuan2_Tutorial/index.md)
- [Qwen Fine-tuning](/Tutorials/Qwen_Tutorial/index.md)