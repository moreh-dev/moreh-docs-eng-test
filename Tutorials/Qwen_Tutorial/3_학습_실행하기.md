---
icon: terminal
tags: [guide]
order: 40
---

# 3. 학습 실행하기

이제 실제로 fine tuning을 실행해 보겠습니다.

## 가속기 Flavor 설정

MoAI Platform에서는 사용자에게 물리 GPU가 노출되지 않습니다. 대신 PyTorch에서 사용 가능한 가상의 MoAI Accelerator가 제공됩니다. 사용자는 가속기의 Flavor를 설정하여 실제 물리 GPU를 어떻게 활용할지 결정할 수 있습니다. 선택한 가속기 Flavor에 따라 총 학습 시간과 GPU 사용 비용이 달라지므로 사용자는 학습 상황에 따라 판단해야 합니다. 사용자의 학습 목표에 맞는 가속기 Flavor를 선택하기 위해 다음 문서를 참고하세요.

- ***[KT Hyperscale AI Computing (HAC) 서비스 가속기 모델 정보](/Supported_Documents/KT_HAC_Models_Info.md)***  문서를 참고하십시오.
- [LLM Fine-tuning 파라미터 가이드](/Supported_Documents/LLM_param_guide.md)

!!!info 
위 문서를 참고하시거나 인프라 제공자에게 각 flavor에 대응되는 GPU 종류 및 개수를 문의하십시오.
!!!

***(모든 문서에 추가될 그림 생성 예정)***

다음 중 하나에 해당하는 flavor를 선택하여 계속 진행하십시오.

- AMD MI250 GPU 16개 사용
    - Moreh의 체험판 컨테이너 사용 시: [!badge variant="secondary" text=“4xLarge”] 선택
    - KT Cloud의 Hyperscale AI Computing 사용 시: [!badge variant="secondary" text=“4xLarge.2048GB”] 선택
- AMD MI210 GPU 32개 사용
- AMD MI300X GPU 8개 사용

앞서 [Qwen Fine-tuning](index.md) 문서에서 MoAI Accelerator를 확인했던 것을 기억하시나요? 이제 본격적인 학습 실행을 위해 필요한 가속기를 설정해보겠습니다.

먼저  `moreh-smi` 명령어를 이용해 현재 사용중인 MoAI Accelerator를 확인합니다.

```bash
$ moreh-smi
11:40:36 April 16, 2024
+-------------------------------------------------------------------------------------------------+
|                                                Current Version: 24.2.0  Latest Version: 24.2.0  |
+-------------------------------------------------------------------------------------------------+
|  Device  |        Name         |     Model    |  Memory Usage  |  Total Memory  |  Utilization  |
+=================================================================================================+
|  * 0     |   MoAI Accelerator  |  xLarge.512GB  |  -             |  -             |  -            |
+-------------------------------------------------------------------------------------------------+
```

현재 사용중인 MoAI Accelerator의 메모리 크기는 512GB입니다. 

`moreh-switch-model` 툴을 사용하여 현재 시스템에서 사용 가능한 가속기 flavor 리스트를 확인할 수 있습니다. 원활한 모델 학습을 위해 `moreh-switch-model` 명령어를 이용해 더 큰 메모리의 MoAI Accelerator로 변경할 수 있습니다. 

```bash
$ moreh-switch-model
Current MoAI Accelerator: xLarge.512GB

1. Small.64GB
2. Medium.128GB
3. Large.256GB
4. xLarge.512GB  *
5. 1.5xLarge.768GB
6. 2xLarge.1024GB
7. 3xLarge.1536GB
8. 4xLarge.2048GB
9. 6xLarge.3072GB
10. 8xLarge.4096GB
11. 12xLarge.6144GB
12. 24xLarge.12288GB
13. 48xLarge.24576GB
```

여기서 번호를 입력하여 다른 flavor로 전환할 수 있습니다. 

이번 튜토리얼에서는 2048GB 크기의 MoAI Accelerator를 이용하겠습니다.

따라서 처음 설정되어 있던 [!badge variant="secondary" text=“xLarge.512GB”] flavor를 [!badge variant="secondary" text=“4xLarge.2048GB”]로 전환한 다음 `moreh-smi` 명령을 사용하여 정상적으로 반영되었는지 확인하겠습니다. 

[!badge variant="secondary" text=“4xLarge.2048GB”] 사용을 위해 8을 입력합니다.


```bash
Selection (1-13, q, Q): 8
The MoAI Accelerator model is successfully switched to  "4xLarge.2048GB".

1. Small.64GB
2. Medium.128GB
3. Large.256GB
4. xLarge.512GB
5. 1.5xLarge.768GB
6. 2xLarge.1024GB
7. 3xLarge.1536GB
8. 4xLarge.2048GB  *
9. 6xLarge.3072GB
10. 8xLarge.4096GB
11. 12xLarge.6144GB
12. 24xLarge.12288GB
13. 48xLarge.24576GB

Selection (1-13, q, Q): q 
```

`q` 를 입력해 변경을 완료합니다.

변경 사항이 잘 반영되었는지 확인하기 위해 다시 `moreh-smi` 명령어를 이용해 현재 사용중인 MoAI Accelerator를 확인합니다.

```bash
$ moreh-smi
23:56:17 April 18, 2024
+-----------------------------------------------------------------------------------------------------+
|                                                    Current Version: 24.2.0  Latest Version: 24.2.0  |
+-----------------------------------------------------------------------------------------------------+
|  Device  |        Name         |       Model      |  Memory Usage  |  Total Memory  |  Utilization  |
+=====================================================================================================+
|  * 0     |   MoAI Accelerator  |  4xLarge.2048GB  |  -             |  -             |  -            |
+-----------------------------------------------------------------------------------------------------+
```

[!badge variant="secondary" text=“4xLarge.2048GB”] 로 잘 변경된 것을 확인할 수 있습니다.

## 학습 실행

주어진 `train_qwen.py` 스크립트를 실행합니다.

```bash
$ cd ~/quickstart
~/quickstart$ python tutorial/train_qwen.py
```

학습이 정상적으로 진행된다면 다음과 같은 로그가 출력될 것입니다. 중간에 파란색으로 표시된 부분을 보시면 Advanced Parallelism 기능이 정상 동작하는 것을 확인할 수 있습니다. 앞서 살펴본 PyTorch 스크립트에서는 AP 코드 한 줄을 제외한 다른 부분에서 GPU 여러 개를 동시에 사용하기 위한 처리가 전혀 없었음을 참고하십시오.

```bash
2024-04-19 01:42:05,158 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp5m113wue
2024-04-19 01:42:05,158 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp5m113wue/_remote_module_non_scriptable.py
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 14966.29it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.28s/it][2024-04-19 01:42:40.510] [info] Got DBs from backend for auto config.
[2024-04-19 01:42:42.093] [info] Requesting resources for MoAI Accelerator from the server...
[2024-04-19 01:42:42.104] [info] Initializing the worker daemon for MoAI Accelerator
[2024-04-19 01:42:47.290] [info] [1/4] Connecting to resources on the server (192.168.110.5:24168)...
[2024-04-19 01:42:47.302] [info] [2/4] Connecting to resources on the server (192.168.110.23:24168)...
[2024-04-19 01:42:47.310] [info] [3/4] Connecting to resources on the server (192.168.110.45:24168)...
[2024-04-19 01:42:47.316] [info] [4/4] Connecting to resources on the server (192.168.110.73:24168)...
[2024-04-19 01:42:47.323] [info] Establishing links to the resources...
[2024-04-19 01:42:47.742] [info] MoAI Accelerator is ready to use.
[2024-04-19 01:42:48.097] [info] The number of candidates is 16.
[2024-04-19 01:42:48.097] [info] Parallel Graph Compile start...
[2024-04-19 01:43:34.235] [info] Elapsed Time to compile all candidates = 46137 [ms]
[2024-04-19 01:43:34.235] [info] Parallel Graph Compile finished.
[2024-04-19 01:43:34.235] [info] The number of possible candidates is 4.
[2024-04-19 01:43:34.235] [info] SelectBestGraphFromCandidates start...
[2024-04-19 01:43:35.506] [info] Elapsed Time to compute cost for survived candidates = 1271 [ms]
[2024-04-19 01:43:35.506] [info] SelectBestGraphFromCandidates finished.
[2024-04-19 01:43:35.506] [info] Configuration for parallelism is selected.
[2024-04-19 01:43:35.506] [info] num_stages : 2, num_micro_batches : 16, batch_per_device : 1, No TP, recomputation : false, distribute_param : true
[2024-04-19 01:43:35.507] [info] train: true

2024-04-19 01:44:38.243 | INFO     | __main__:main:150 - [Step 1/144] | Loss: 1.34375 | Duration: 57.79 | Throughput: 9072.25 tokens/sec
2024-04-19 01:44:53.592 | INFO     | __main__:main:150 - [Step 2/144] | Loss: 0.83984375 | Duration: 7.42 | Throughput: 70685.21 tokens/sec
2024-04-19 01:45:11.438 | INFO     | __main__:main:150 - [Step 3/144] | Loss: 0.9921875 | Duration: 10.37 | Throughput: 50536.92 tokens/sec
2024-04-19 01:45:28.565 | INFO     | __main__:main:150 - [Step 4/144] | Loss: 0.98828125 | Duration: 9.84 | Throughput: 53281.45 tokens/sec
2024-04-19 01:45:46.302 | INFO     | __main__:main:150 - [Step 5/144] | Loss: 0.75390625 | Duration: 10.41 | Throughput: 50347.46 tokens/sec
2024-04-19 01:46:04.209 | INFO     | __main__:main:150 - [Step 6/144] | Loss: 0.69921875 | Duration: 10.60 | Throughput: 49452.14 tokens/sec
2024-04-19 01:46:22.198 | INFO     | __main__:main:150 - [Step 7/144] | Loss: 0.53515625 | Duration: 10.65 | Throughput: 49214.62 tokens/sec
2024-04-19 01:46:37.560 | INFO     | __main__:main:150 - [Step 8/144] | Loss: 0.609375 | Duration: 7.67 | Throughput: 68339.57 tokens/sec
2024-04-19 01:46:55.414 | INFO     | __main__:main:150 - [Step 9/144] | Loss: 0.482421875 | Duration: 10.43 | Throughput: 50256.04 tokens/sec
...
2024-04-19 02:22:56.201 | INFO     | __main__:main:150 - [Step 139/144] | Loss: 0.51171875 | Duration: 8.05 | Throughput: 65134.47 tokens/sec
2024-04-19 02:23:13.305 | INFO     | __main__:main:150 - [Step 140/144] | Loss: 0.5546875 | Duration: 9.57 | Throughput: 54804.19 tokens/sec
2024-04-19 02:23:28.836 | INFO     | __main__:main:150 - [Step 141/144] | Loss: 0.494140625 | Duration: 7.58 | Throughput: 69209.20 tokens/sec
2024-04-19 02:23:47.302 | INFO     | __main__:main:150 - [Step 142/144] | Loss: 0.546875 | Duration: 10.52 | Throughput: 49843.95 tokens/sec
2024-04-19 02:24:05.560 | INFO     | __main__:main:150 - [Step 143/144] | Loss: 0.515625 | Duration: 10.67 | Throughput: 49114.75 tokens/sec
2024-04-19 02:24:20.923 | INFO     | __main__:main:150 - [Step 144/144] | Loss: 0.7421875 | Duration: 7.68 | Throughput: 68246.97 tokens/sec
total_step: 144
Training Done
Saving Model...
Model saved in ./qwen_code_generation
```

Loss 값이 아래와 같이 나타나며 정상적으로 학습이 진행되고 있음을 확인할 수 있습니다. 

![](loss.png)

학습 중에 표시되는 throughput은 해당 PyTorch 스크립트를 통해 초당 몇 개의 토큰을 학습하고 있는지를 의미합니다.

- AMD MI250 GPU 16개 사용 시: 약 59,000 tokens/sec

GPU 종류 및 개수에 따른 대략적인 학습 소요 시간은 다음과 같습니다.

- AMD MI250 GPU 16개 사용 시: 약 40분

## 학습 중에 가속기 상태 확인


학습 도중에 터미널을 하나 더 띄워서 컨테이너에 접속한 후 `moreh-smi` 명령을 실행하시면 다음과 같이 MoAI Accelerator의 메모리가 차지되는 것을 확인할 수 있습니다. 실행 로그를 보면 초기화 과정이 완료되고 Loss가 출력되는 도중에 확인해 보세요.

```bash
$ moreh-smi
01:49:22 April 19, 2024
+-----------------------------------------------------------------------------------------------------+
|                                                    Current Version: 24.2.0  Latest Version: 24.2.0  |
+-----------------------------------------------------------------------------------------------------+
|  Device  |        Name         |       Model      |  Memory Usage  |  Total Memory  |  Utilization  |
+=====================================================================================================+
|  * 0     |   MoAI Accelerator  |  4xLarge.2048GB  |  853677 MiB    |  2096640 MiB   |  100 %        |
+-----------------------------------------------------------------------------------------------------+

Processes:
+------------------------------------------------------------------------------------+
|  Device  |  Job ID  |    PID    |             Process             |  Memory Usage  |
+====================================================================================+
|       0  |  975583  |  4090049  |  python tutorial/train_qwen.py  |  853677 MiB    |
+------------------------------------------------------------------------------------+
```

