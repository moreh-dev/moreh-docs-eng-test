[[{"l":"Moreh Documentation Hub","p":["Getting Started (HAC)","HAC 서버 접속 및 사용하기","GPU 자원 변경 (moreh-switch-model)","GPU 자원 모니터링 (moreh-smi)","Docker 이미지로 Moreh 실행하기 (moreh-docker-run)","Reference Model 학습하기","Kubernetes Cluster에서 Moreh 솔루션 사용하기","Troubleshooting","Products","Moreh Model Hub","Platform Cloud Service"]}],[{"l":"About MoAI"},{"i":"moreh-ai-appliance-for-ai-accelerators-란","l":"Moreh AI appliance for AI accelerators 란?","p":["MoAI( Moreh AI appliance for AI accelerators)는 클러스터에 장착된 다양한 종류의 가속기에서 PyTorch 혹은 TensorFlow로 작성된 애플리케이션을 수정 없이 실행시키는 분산 딥러닝 프레임워크입니다.","MoAI Platform을 통해 사용자는 컴파일러 기술의 도움으로 단일 칩에서 대형 클러스터에 이르기까지 다양한 프로세서와 다양한 시스템 규모에서 AI 문제에 집중할 수 있습니다. 따라서 인프라 소프트웨어 간에 충돌 및 호환 문제를 완전히 해결하여 다양한 인공지능 제품·서비스와 기술개발을 촉진합니다.","또한 연산 실행 시에만 GPU 자원을 할당하여 합리적인 비용으로 AI 애플리케이션이 GPU 연산 자원을 효율적으로 사용할 수 있습니다."]},{"l":"Moreh 솔루션이 선택받는 이유","p":["프레임워크 호환성: MoAI는 PyTorch와 TensorFlow를 비롯한 표준 딥러닝 프레임워크와의 완전한 호환성을 제공하여 별도의 코드 수정 없이 중요한 AI 문제 해결에 집중할 수 있습니다.","가속기 이식성: MoAI의 유연성은 OpenCL을 포함한 다양한 디바이스 백엔드를 지원하여 다양한 GPU 및 NPU와 같은 가속기에서 AI 애플리케이션을 실행할 수 있도록 합니다. 소프트웨어 호환성에 대한 걱정 없이 비용 효율적인 AI 인프라를 구축할 수 있습니다.","초대형 모델 개발을 위한 GPU 클러스터: 대형 딥러닝 모델에 대응할 수 있는 대규모 GPU 클러스터링을 지원하여 차세대 AI 모델과 인프라 구축을 지원합니다.","애플리케이션 가상화: MoAI는 사용자를 물리적인 하드웨어 가속기와 분리함으로써 프로그램 실행 중에만 가상 디바이스에서 GPU 리소스를 할당합니다. 따라서 하드웨어 종속성 없이 유연성을 향상시켜 AI 클라우드 서비스에서 가속기 활용도를 크게 향상시킵니다.","단일 디바이스 추상화: MoAI는 대규모 클러스터 시스템을 단일 디바이스로 캡슐화하여 사용자가 다중 가속기 및 노드 간의 병렬화를 걱정하지 않고도 AI 애플리케이션을 개발할 수 있게 합니다.","Copyright © 2022 Moreh Corporation"]}],[{"l":"MoAI 사용하기"},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Getting Started","p":["이 매뉴얼은 개발자가 터미널에 접속해서 MoAI 플랫폼을 이용하는 Quickstart 가이드를 제공합니다."]},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 해당 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Docker 이미지로 Moreh 실행하기"},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 방법"},{"l":"moreh-docker-run","p":["MoAI Platform은 도커 컨테이너 안에서 AI 가속기를 사용하는 PyTorch 프로그램을 실행할 수 있도록 전용 도커 이미지를 제공하고 있습니다. VM에서 다음의 명령어들을 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","moreh-docker-run 은 도커의 권한이 필요한 실행 스크립트입니다. 따라서 아래와 같은 명령어로 사전에 docker 권한 수정이 필요합니다. sudo chmod 666 /var/run/docker.sock","moreh-docker-run 명령어를 사용해 Moreh 솔루션이 담긴 도커 이미지를 실행합니다. 추가적으로 다른 옵션값을 안주고 실행했을 경우에는 현재까지 배포된 Moreh 솔루션 이미지 중 가장 최신 버전 도커 이미지를 실행하게 됩니다.","moreh-docker-run 명령어 뒤에 추가 옵션을 통해 도커 이미지만 다운로드 받기, 버전 확인 등을 실행할 수 있습니다.","moreh-docker-run 명령어는 Moreh 솔루션 23.11.0 버전 이후로는 기본적으로 pytorch 1.13.1 버전의 도커 이미지를 제공하고 있습니다. 23.11.0 버전 이전으로는 기본적으로 pytorch 1.7.1 버전의 도커 이미지를 제공하고 있습니다."]},{"l":"Supported Arguments","p":["pullonly (-p)","해당 옵션값을 추가로 줄경우, Moreh 솔루션 이미지를 바로 실행하지 않고 단순히 다운로드하게 됩니다.","해당 옵션값을 사용할 때는 --target 옵션값을 추가로 사용할 수 있으며, --target 옵션 값 뒤에는 아래 예시 명령어와 같이 버전을 명시해줘야 합니다. 만일 없을 경우 최신버전 이미지를 가져오게 됩니다.","version (-v)","Moreh 솔루션 도커 이미지 버전명을 보여줍니다.","—-target {VERSION}","특정 Moreh 솔루션 버전의 도커 이미지를 실행합니다. 기본값은 최신 모레 솔루션 버전이 들어가게 됩니다.","--torch {VERSION}","Moreh 솔루션 도커 이미지내에 설치된 torch 버전을 명시합니다. 기본값은 1.13.1입니다. ( Moreh솔루션 23.11.0 이후)","--tensorflow {VERSION}","Moreh 솔루션 도커 이미지 내에 설치된 Tensorflow 버전을 명시합니다. 기본값은 2.9.0입니다. 현재 Moreh 솔루션에서는 tensorflow 2.9.0 버전만 제공 중 인 점 참고부탁드립니다."]},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 시나리오","p":["VM에서 다음과 같이 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","만일, 특정 버전의 Moreh 솔루션 이미지를 실행하고 싶다면, 위 명령어 뒤에 —-target 이라는 옵션을 추가하여 원하시는 Moreh 솔루션 버전 도커 이미지를 실행하실 수 있습니다. 만일 해당 옵션 없이 moreh-docker-run 을 실행하면 현재까지 배포된 Moreh 솔루션 중 최신 버전으로 이미지를 실행하게 됩니다.","컨테이너 안에서 AI 가속기 정보를 조회하고 PyTorch 프로그램을 실행시킬 수 있습니다.","컨테이너 안에서 인식되는 AI 가속기는 VM에 할당된 AI 가속기와 동일한 것입니다. VM에서 가속기 모델을 변경하면 컨테이너 안에서도 적용되며 그 반대도 마찬가지입니다. 또한 VM에서 AI 가속기를 사용하는 동안은 컨테이너 안에서는 AI 가속기를 사용할 수 없으며 이것 역시 반대도 마찬가지입니다. 예를 들어 VM에서 AI 가속기를 사용하는 pytorch-sample.py 프로그램이 실행 중인 동안 컨테이너에서 AI 가속기를 사용하는 다른 프로그램을 실행할 경우, 아래와 같은 메시지를 출력하고 VM에서 pytorch-sample.py 프로그램이 끝날 때까지 대기하게 됩니다.","이 문서의 나머지 부분에서는 MoAI Platform를 위한 Docker 컨테이너를 실행하는 과정을(즉, moreh-docker-run 명령이 내부적으로 하는 일을) 단계별로 자세히 설명합니다.","\uD83D\uDCA1 도커를 사용하지 않고도 VM 안에서 바로 AI 가속기를 사용해 PyTorch 프로그램 실행이 가능합니다. 이 문서는 특별히 도커 기반으로 실행해야 하는 애플리케이션이 있는 분들을 대상으로 합니다."]},{"l":"도커 이미지 내려받기","p":["위와 다르게, 단순히 Moreh 솔루션 이미지만 내려받고 싶으시다면 —-pullonly (-p) 옵션을 활용하여 이미지를 내려받을수 있습니다.","해당 명령어도 위와 동일하게 만일 특정 버전의 Moreh 솔루션 이미지를 내려받고싶다면, —-target 옵션 추가로 이를 수행하실수가 있습니다. 만일 해당 옵션없이 moreh-docker-run --pullonly 을 실행하면 현재까지 배포된 Moreh 솔루션중 최신 버전으로 이미지를 실행하게 됩니다."]},{"l":"Docker Container runtime으로 컨테이너 시작","p":["moreh-docker-run 외에 다음과 같이 docker run 명령으로 동일하게 컨테이너를 실행할 수 있습니다. 이 때 다음의 옵션을 포함시켜야 합니다.","v /etc/moreh:/etc/moreh"]}],[{"i":"gpu-자원-모니터링-moreh-smi","l":"GPU 자원 모니터링 (moreh-smi)","p":["$ MOREH_VISIBLE_DEVICE=0 python train_your_script_00.py$ MOREH_VISIBLE_DEVICE=1 python train_your_script_01.py","1~ 5번 명령어를 통해 단일 SDA 디바이스를 설정하고 모니터링 할 수 있으며, 6~8번 명령어를 통해 다중 SDA 디바이스를 설정할 수 있습니다.","AI 가속기 디바이스, 즉 Software-Defined Accelerator(이하 SDA)는 아래 8가지 명령어로 사용할 수 있습니다.","Device ID 0번 SDA → train_your_script_00.py 을 실행함과 동시에","Device ID 1번 SDA → train_your_script_01.py 을 실행할 수 있습니다.","MoAI Platform의 다중 SDA는 Token 1개당 1개 이상의 디바이스 종류를 생성/삭제할 수 있는 기능을 지원합니다. 하나 이상의 디바이스가 지원되는 것과 동시에 사용자 친화적으로 인터페이스가 구성되어 하나의 Token으로 여러 개의 디바이스의 프로세스를 유연하게 실행할 수 있습니다.","moreh-smi --reset- SDA 프로세스 종료하기","moreh-smi -i- SDA 활용 상태 모니터링하기","moreh-smi -p- SDA 상세 하드웨어 상태 모니터링하기","moreh-smi -t- SDA 토큰 정보 확인하기","moreh-smi device --add- SDA 생성하기","moreh-smi device --rm- SDA 삭제하기","moreh-smi device --switch- SDA 디바이스 기본값 변경하기","moreh-switch-model- SDA 변경하기","SDA 복제 기능( Duplicable) 설정을 통해 최대 횟수만큼 병렬 학습을 진행할 수 있으나 해당 기능은 관리자를 통해 설정 요청 부탁드립니다.","VM 1개를 여러 명이 동시에 공유해야 할 경우, VM의 자원을 효율적으로 활용할 수 있습니다.","각 명령어의 다양한 옵션에 대해서 더 자세히 알고 싶다면 moreh-smi --help 로 확인 가능합니다.","단일 SDA를 사용한다면 moreh-switch-model 명령어를 통해 하나의 GPU 자원의 종류를 선택할 수 있습니다. 반면에 다중 SDA를 사용한다면, 하나의 VM에서 여러 개의 SDA 디바이스를 동시에 선택하고 실행할 수 있습니다.","단일 SDA와 다중 SDA의 차이점","실행 프로세스","예를 들어 아래와 같이 moreh-smi device --add {model_id} 로 SDA를 추가하여 총 2개의 SDA가 설정되었다면 1개의 Token에 대해 VM 한 곳에서 동시에 2개의 프로세스를 실행할 수 있습니다.","위 명령어로 여러 개의 GPU 묶음을 할당하여 병렬 학습을 진행할 수 있습니다.","위와 같은 상황에서 병렬 실행을 통해 동시에 GPU 자원을 사용할 수 있습니다.","이제 개별 명령어에 대해 설명 드리겠습니다.","하나의 VM에서 여러 개의 SDA 디바이스를 동시에 실행함으로써 아래와 같은 다양한 장점을 얻을 수 있습니다.","학습에 사용할 하이퍼파라미터를 탐색하기 위한 Hyperparameter Tuning 작업을 여러 번의 학습을 동시에 실행하여 최적의 설정 값을 찾을 수 있습니다."]},{"l":"1. SDA 활용 상태 모니터링하기 moreh-smi","p":["Moreh 소프트웨어 툴은 moreh-smi 명령어를 통해 현재 선택된 SDA 모델, 실행 중인 학습 프로세스, GPU Resource를 얼마나 할당받고 있는지를 확인할 수 있습니다."]},{"i":"2-sda-token-정보-확인하기-moreh-smi--p","l":"2. SDA token 정보 확인하기 moreh-smi -p","p":["moreh-smi -p 명령어로 현재 선택된 SDA 모델에 할당된 노드의 아래와 같은 정보를 확인할 수 있습니다."]},{"i":"3-sda-token-정보-확인하기-moreh-smi---token","l":"3. SDA token 정보 확인하기 moreh-smi --token","p":["Token 값은 사용자를 식별하기 위한 해시 값이며 사용자마다 고유 값을 가지고 있습니다. Token은 일반적으로 사용자의 가상 머신(VM) 안에 위치하며, 모레솔루션을 사용할 서버는 Token 값을 바탕으로 사용자를 식별하고 학습이 실행되므로, Token 없이는 GPU 연산 및 Python 애플리케이션을 실행할 수 없습니다.","moreh-smi --token 또는 moreh-smi -t 명령어로 VM에서 Token 설정 상태를 확인할 수 있습니다.","터미널에 해당 명령어를 입력하면 어떤 Token이 설정되어있는지 확인할 수 있습니다."]},{"l":"4. SDA 변경하기 moreh-switch-model","p":["moreh-switch-model 명령어를 통해 SDA 디바이스를 변경하여 가상 머신에서 사용할 GPU 리소스의 양을 조정할 수 있습니다.","moreh-switch-model 명령어를 사용하면 아래와 같은 입력창이 나타납니다.","1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “The KT AI Accelerator model is successfully switched to .” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA 모델로 변경됩니다. 여기서는 1번 Small.64GB 로 SDA 모델을 변경해보겠습니다.","변경을 계속하거나 q 또는 Q 를 통해 SDA 모델 변경을 종료할 수 있습니다."]},{"i":"5-sda-프로세스-종료하기-moreh-smi---reset","l":"5. SDA 프로세스 종료하기 moreh-smi --reset","p":["moreh-smi --reset 또는 moreh-smi -r 명령어를 통해 SDA 디바이스를 사용하고 있는 프로세스를 종료할 수 있습니다.","다음은 학습 중 종료한 예시입니다.","“Device release success.” 메시지와 함께 종료된 걸 확인할 수 있습니다.","아래와 같이 프로세스가 존재하지 않는 경우에는 “Device release failed. (Not running job.)” 메시지와 함께 실패합니다."]},{"i":"6-sda-추가하기-moreh-smi-device---add","l":"6. SDA 추가하기 moreh-smi device --add","p":["가상 머신(VM)이 생성된 직후에는 SDA는 1개까지만 기본값으로 제한되어 있습니다. 2개 이상의 SDA 사용이 필요한 경우 관리자에게 문의하여 제한값 설정을 요청 부탁드립니다.","하나의 VM 내에서는 최대 5개까지의 SDA를 생성할 수 있습니다.","Token의 제한 값이 변경된 이후 moreh-smi device --add 명령어로 SDA를 추가할 수 있습니다.","다음은 SDA를 추가하는 예제입니다.","moreh-smi device --add 커맨드를 입력하면 moreh-switch-model 과 동일한 인터페이스가 나타납니다. 1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “Create device success.” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA가 생성됩니다. 여기서는 3번 Large.256GB 로 SDA를 하나 더 생성해 보겠습니다.","moreh-smi device --add {model_id} 명령어를 통해 대화형 입력창 없이 바로 SDA를 생성할 수도 있습니다.","여기서 {model_id} 는 SDA 모델의 번호를 의미하며, Large.256GB 의 경우에는 ‘3’ 이 됩니다."]},{"i":"7-생성된-sda-디바이스-삭제하기-moreh-smi-device---rm","l":"7. 생성된 SDA 디바이스 삭제하기 moreh-smi device --rm","p":["생성된 SDA 디바이스를 삭제하려면 moreh-smi device --rm 명령어를 사용하면 됩니다.","moreh-smi device --rm {Device_ID} 명령어로 특정 Device_ID에 해당하는 SDA를 삭제해보겠습니다.","만약 help message에 device --add 와 같은 옵션의 도움말이 등장하지 않는다면 사용자 token에 대한 최대 디바이스 개수가 1로 설정된 것이므로 고객지원을 요청 부탁드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"l":"8. SDA 생성된 디바이스 기본값 변경하기","p":["moreh-smi device --switch {Device_ID} 명령어를 입력하면 이미 생성된 디바이스의 ID에 해당하는 디바이스로 변경됩니다.","moreh-smi device --switch {Device_ID} 를 통해 0번 Medium.128GB 을 기본 SDA로 변경해 보겠습니다.","생성된 SDA 모델 리스트 중 디바이스에 해당하는 정수를 입력하면 “Switch current device success.” 메시지와 함께 입력된 SDA가 기본 디바이스로 설정됩니다. 학습 프로세스 실행하면 설정한 기본 SDA 디바이스를 사용합니다.","여기서는 다시 1번 Medium.128GB 을 기본 SDA 디바이스로 변경해 보겠습니다.","이제 학습 실행 시 기본 값으로 1번 디바이스를 사용하게 됩니다."]}],[{"l":"GPU 자원 변경하기"},{"l":"moreh-switch-model","p":["VM에서 사용할 GPU의 개수를 조정할 수 있습니다. 다음 명령어(moreh-switch-model)를 통해 SDA를 변경할 수 있습니다.","현재 지원하는 SDA는 다음(Figure 1)과 같습니다. 번호로 SDA을 선택할수있고, q(또는 Q)로 대화를 종료 할 수 있습니다.","제일 작은 단위의 SDA는 Small.64GB이며 총 64GB 메모리를 가지고 있습니다. 그 이상 SDA는 Small.64GB의 배수만큼의 계산능력과 메모리를 가집니다. 예를 들어 Large.256GB는 Small.64GB에 비해 4배의 계산능력과 메모리를 가집니다."]}],[{"l":"Moreh 솔루션 업데이트 하기","p":["Moreh 솔루션은 주기적으로 업데이트되면서 솔루션의 전반적 성능이 개선되고 있습니다. Moreh 솔루션을 활용하는 방식에 따라 특정 버전의 Moreh 솔루션만을 사용하실 수 있지만, 가급적 최신 Moreh 솔루션을 사용하시는 것을 권장하고 있습니다. Moreh 솔루션을 업데이트하시면 사용하시는 환경의 Deep learning framework(PyTorch, TensorFlow) 및 Moreh driver 등의 필수 패키지들이 업데이트됩니다."]},{"l":"update-moreh","p":["Moreh 솔루션은 다음 명령어를 통해 업데이트하실 수 있습니다.","기본적으로 위 명령어 실행 시 현재까지 배포된 버전 중 최신 버전으로 업데이트를 진행합니다.","-target","Moreh 솔루션을 특정 버전으로 다운(업)그레이드를 할 수 있는 옵션입니다. --target 옵션 뒤에는 특정 버전을 아래와 같이 기입해주시면 됩니다."]},{"l":"Deep Learning Framework 버전 변경하기","p":["Moreh 솔루션은 Pytorch 1.7.1 버전뿐만이 아닌 Pytorch 1.10.0, 1.13.1 버전과 Tensorflow 2.9.0 버전에 대해서도 제공하고 있습니다.","다른 버전의 Framework 설치를 위한 옵션은 다음과 같습니다."]},{"l":"PyTorch 버전 변경하기"},{"l":"TensorFlow 버전 변경하기","p":["\uD83D\uDCA1 Tensorflow와 Pytorch 1.10.0 혹은 1.13.1 버전은 동시에 설치를 할 수 없습니다."]}],[{"l":"K8S Cluster에서 Moreh 솔루션 사용하기"},{"l":"K8S Cluster에 접근하기 위한 서버 접속","p":["K8S Cluster를 사용하기 위해 moreh-k8s-master-vm01 서버로 접속해야합니다.","관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","관리자가 해당 VM 접속정보를 이용자에게 제공하였다고 가정해보겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"Pod을 띄우기 위한 Manifest 파일 작성","p":["$ kubectl apply -f {파일 경로}","$ kubectl exec -it {pod 이름} -n {namespace} -c {container 이름} -- /bin/bash","$ kubectl get pods -n {metadata.namespace}","apply: 해당 액션으로 쿠버네티스 리소스를 생성/수정","f: 파일 경로","K8S 클러스터 안에서 pod을 띄우기 위해 다음과 같이 작성합니다.","K8S 클러스터에 pod을 생성하기 위해 다음의 명령어로 위에서 작성한 manifest 파일을 적용합니다.","K8S 클러스터에 해당 pod이 생성되었는지 다음의 명령어로 확인합니다.","Manifest 파일은 쿠버네티스 오브젝트를 관리하기 위한 선언적 specification을 포함하는 YAML 파일입니다.","metadata.name: pod의 이름","spec.template.spec.containers[0].env[0].value: 사용할 토큰","spec.template.spec.containers[0].image: Moreh 솔루션의 도커 이미지","spec.template.spec.containers[0].name: container의 이름","먼저 모레 솔루션이 작동하는지 여부를 moreh toolkit을 활용해 확인해봅니다.","사용자가 작성해야 할 주요 key는 다음과 같습니다.","생성한 pod에 다음의 명령어로 접속합니다."]},{"l":"Moreh Toolkit 사용","p":["moreh-smi","moreh-switch-model","만약 moreh tools를 실행했을 때 다음과 같이 ‘moreh::InvalidToken’ 에러가 발생한 경우 토큰 설정을 해주어야 합니다.","컨테이너 내부에서 /etc/moreh/token 에 할당받은 토큰을 입력하면 위의 문제가 해결됩니다."]},{"l":"Duplicable SDA 설정","p":["추론 시스템을 구축하는 경우, 하나의 SDA에서 여러 프로세스를 만들 필요가 있을 수 있습니다. 이러한 경우 duplicable SDA 설정을 통해 하나의 SDA에서 다수의 GPU 활용 프로그램을 실행할 수 있습니다.","Duplicable SDA는 moreh-smclient 를 통해 설정할 수 있습니다."]},{"l":"PyTorch 학습","p":["샘플 코드인 pytorch-sample.py를 사용해 학습을 진행하면 다음과 같은 결과를 얻을 수 있습니다."]},{"l":"사용 완료한 Pod 제거","p":["pod을 제거하기 위해서는 먼저 deployment를 삭제해야합니다.","$ kubectl delete pod {pod 이름} -n {namespace} 로 pod을 삭제하면 deployment 컨트롤러가 새 pod을 생성하여 복제본 수를 유지하려고 하기 때문입니다.","다음의 명령어로 deployment를 삭제합니다.","$ kubectl delete deployment {deployment 이름} -n {namespace}","그 후 pod을 제거합니다.","$ kubectl delete pod {pod 이름} -n {namespace}","pod이 삭제되었는지 확인합니다.","$ kubectl get pods -n {namespace}"]}],[{"l":"Large Model 학습하기","p":["LM(Large Model) 이란?","Moreh framework 에서 학습, 추론이 가능한 대형 추론 모델을 의미합니다. 정기적으로 프레임워크와 함께 배포되며 Moreh 솔루션에서 딥러닝 학습에 필수적인 단계들을 수행할 수 있는 대형 언어 및 추론 모델을 다운로드할 수 있습니다. 따라서 사용자는 Large Model을 활용하여 직접 코딩하지 않아도 바로 학습, 추론을 수행할 수 있습니다.","Moreh 솔루션에서 지원하는 AI 프레임워크인 PyTorch와 TensorFlow, 그리고 학습 실행 방법을 설명 드리겠습니다."]},{"l":"PyTorch"},{"l":"1. Large Language Model 코드 다운로드","p":["아래 간단한 명령어 한 줄로 다양한 Large Model 코드를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 RM Code 설치 파일을 다운로드하고 실행하여 학습에 필요한 파일을 설치합니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다.","get-reference-model 명령어는 sudo 없이 사용하시길 권장드립니다. sudo 명령어가 포함될 경우, 실행 시 아래와 같은 에러가 발생할 수 있습니다."]},{"l":"2. Large Language Model 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"l":"3. 제공되는 모든 Large Model 목록 확인하기","p":["현재 어떤 모델 코드들이 제공되는지 궁금하시다면 —-show(또는 -s) 옵션을 이용하여 확인할 수 있습니다. 가장 범용적으로 쓰이는 딥러닝 모델과 Moreh 솔루션을 이용한 딥러닝 학습 모범 사례로 쓰일만한 안전한 모델들이 목록에 나타납니다."]},{"l":"4. Large Model 설치 파일 설정하기","p":["모델 설치 파일 (.sh) 에 대해서 수정 사항이 필요할 경우엔 아래와 같이 --download-only 옵션을 추가하여 모델 설치 파일만 다운로드 하실수도 있습니다. 해당 옵션을 추가하고 실행하면 실행 경로에 install_MODEL_NAME.sh 파일이 생성됩니다.","다음은 install_resnet.sh 파일을 다운받는 명령어 예시입니다.","모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 ResNet 모델을 설치하는 예시입니다.","—-download-only 옵션과 —-download-dir 옵션은 같이 사용하실 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 instsall_resnet.sh 파일만 다운로드하는 명령어 예시입니다."]},{"l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]},{"l":"Tensorflow"},{"l":"1. TensorFlow 가상 환경","p":["처음 VM 생성 시 기본으로 tensorflow 이름의 Tensorflow용 conda 가상환경이 존재합니다. Tensorflow conda 환경이 없는 사용자 분들은 아래와 같은 방법으로 TensorFlow를 위한 가상환경을 생성하시기 바랍니다."]},{"l":"2. Tensorflow Large Model 코드 다운로드","p":["get-reference-model 명령어 한 줄로 다양한 Large Model(이하 LM) Code를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 Large Model Code 설치 파일 및 샘플 데이터을 다운로드하게 되며, 동시에 해당 설치 파일을 실행시켜 실행환경을 세팅해줍니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다."]},{"l":"3. Large Model 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"i":"4-large-model-설치-파일-설정하기-1","l":"4. Large Model 설치 파일 설정하기","p":["모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 /data/tf-rm 경로에 ResNet 모델 파일을 다운받는 명령어 예시입니다."]},{"i":"5-모델-학습-시작하기-1","l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"i":"hyperparameter-변경하기-1","l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]}],[{"l":"Troubleshooting","p":["Moreh 솔루션 사용 시 발생할 수 있는 일반적인 오류에 대한 해결 방안을 제공합니다."]},{"i":"two-or-more-processes-cannot-use-kt-ai-accelerator-at-the-same-time","l":"Two or more processes cannot use KT AI Accelerator at the same time.","p":["SDA가 이미 사용 중인 경우, Two or more processes cannot use KT AI Accelerator at the same time. 경고 메시지가 출력될 수 있습니다. moreh-smi --reset 명령을 실행하여 강제로 SDA를 해제할 수 있습니다. 동일한 토큰 값으로 여러 개의 Pod를 띄워 SDA를 동시에 사용하려는 경우(e.g., K8s 기반 서비스) KT Cloud에 문의하여 토큰의 duplicable 설정을 받으시기 바랍니다.","moreh-smi --reset 으로 강제로 SDA 해제"]},{"i":"morehinvalidtoken","l":"moreh::InvalidToken.","p":["SDA 토큰이 적용되지 않아 발생하는 오류 메시지입니다. 환경 변수 MOREH_SDA_TOKEN 를 할당받은 토큰으로 설정한 후, 모레 솔루션을 사용하시면 해당 오류가 해결됩니다."]},{"i":"update-moreh---tensorflow-명령줄-실행-시-업데이트가-진행되지-않거나-python-패키지가-잡히지-않는-경우","l":"update-moreh --tensorflow 명령줄 실행 시 업데이트가 진행되지 않거나 Python 패키지가 잡히지 않는 경우.","p":["해당 문제는 .local 폴더와 관련된 문제일 수 있습니다. 해당 폴더 ~/.local/lib 과 ~/.local/bin 을 삭제 후 재시도해보시기 바랍니다."]},{"l":"사용자 VM에서 Python 프로세스가 종료되지 않고 남아있는 경우","p":["모델 학습을 강제 중단 혹은 종료한다면 비정상 종료된 Python 프로세스가 종료되지 않고 남아있을 수 있습니다.","pkill python 혹은 vkill {pid} 를 통해 종료하시길 바랍니다."]},{"l":"SSH 클라이언트와 통신이 끊겨 학습이 종료되는 경우","p":["보안을 위해 일정 시간 터미널에서 동작이 없다면 SSH 클라이언트와 통신이 끊기게 됩니다.","위와 같이 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"i":"2380-이전-버전을-update-moreh-명령어로-설치할-때-moreh-솔루션이-제대로-설치되지-않는-경우","l":"23.8.0 이전 버전을 update-moreh 명령어로 설치할 때 Moreh 솔루션이 제대로 설치되지 않는 경우","p":["update-moreh 명령어 외에 파이썬 패키지 관리자인 pip을 사용하여 Moreh 솔루션을 동일하게 업데이트할 수 있습니다.","update-moreh 로 솔루션 설치가 제대로 이루어지지 않는다면 다음의 pip install 을 통해 솔루션을 설치해보시기 바랍니다."]},{"l":"Moreh 솔루션 버전을 roll back하려 할 때 update-moreh가 제대로 동작하지 않는 경우","p":["동일한 버전으로 다시 Moreh 솔루션을 설치하고 싶은 경우나, 원하는 타깃 버전으로 업(다운)그레이드가 정상적으로 되지 않을 경우 -force 옵션을 통해 강제로 Moreh 솔루션의 업데이트를 진행할 수 있습니다.","하지만 가급적이면 Moreh 솔루션 사용시 -force command는 지양하고 있으니 버전이슈로 인한 에러가 발생한 경우 고객지원을 요청 바랍니다."]}],[{"l":"Products","p":["Platform Cloud Service"]},{"i":"badge-platform-cloud-service-platformcloudservice-md","l":"[!badge Platform Cloud Service](platformcloudservice.md)"},{"i":"badge-ai-model-hub-aimodelhub-md","l":"[!badge AI Model Hub](Aimodelhub.md)"},{"i":"badge-moreh-api-morehapi-md","l":"[!badge Moreh API](morehapi.md)"},{"i":"badge-moreh-web-console-webconsole-md","l":"[!badge Moreh Web Console](webconsole.md)"}],[{"l":"Moreh AI Model Hub","p":["Chatbot Comparison: 동일한 모델에 대한 파라미터 별 학습 시간 및 생성된 답변의 질을 비교하여 각 모델의 성능 차이를 비교할 수 있습니다.","Chatbot_Small, Chatbot_Medium, Chatbot_Large: 챗봇의 명칭은 사용된 언어 모델의 크기에 따라 구분되었습니다. 3개의 챗봇 모두 대형 언어 데이터를 기반으로 문맥을 이해하고 문장을 생성하며 다양한 주제에 대한 정보 제공, 질문 응답, 일상 대화를 통해 사용자와 상호작용합니다.","Code Generator: 사용자가 지정한 규칙 및 요구 사항에 따라, 프로그래밍 코드를 자동으로 생성하여 제공합니다.","Compare Model","Debugging: 입력한 함수를 디버깅 가능한 test case를 작성합니다.","Explain code: 사용자가 입력한 코드가 어떻게 작동하는지 설명합니다.","Generate code: 사용자가 작성한 주석을 수행하는 코드 작성합니다.","Image Generate AI","MAMH 의 목표는 AMD GPU만으로도 학습이 가능한 AI 모델을 사용하고 공유하는 과정을 단순화하고 개선하는 것입니다. 이 서비스는 다음 목적을 충족하기 위해 탄생하였습니다:","Moreh AI Model Hub 는 대규모 모델을 종합적으로 제공하는 서비스로, 언어뿐만 아니라 이미지 생성 및 모델 비교와 같은 다양한 작업을 수행합니다.","Moreh AI Model Hub(MAMH) 작동 방식","Moreh AI Model Hub(MAMH)는 무엇인가요?","Moreh AI Model Hub는 텍스트 및 이미지를 생성하고 언어를 번역하며 다양한 종류의 창의적인 콘텐츠를 작성하는 등의 작업을 하는 도구입니다.","Multi Modal AI","Random Image: 무작위로 선택된 이미지를 제공하는데, 일반적으로 사용자의 요청에 따라 랜덤하게 이미지를 생성합니다.","Text Generate AI","Text to Image Editing: 사용자가 입력한 텍스트 설명에 따라 이미지를 편집합니다.","Text to Image: 텍스트 입력을 기반으로 시각적 콘텐츠를 생성합니다.","Visual Question Answering: 이미지와 관련된 질문에 대답하는 기능을 제공합니다. 사용자가 이미지에 대한 질문을 하면, VQA는 이미지를 분석하고 자연어 처리 기술을 활용하여 해당 질문에 대한 응답을 생성하여 제공합니다.","공동 작업 및 공유: 모델 허브는 사용자 간에 AI 모델을 공동으로 작업하고 공유하는 데 편리한 방법을 제공합니다. 모델을 만들고 수정한 후 다른 사용자와 공유하거나 공동 작업할 수 있습니다. (To Be Determined)","모델 검색 및 선택의 용이성: Model Hub는 하드웨어 자원 및 시간 대비 학습 성능이 좋은 대규모 생성형 AI 모델을 검색하고 선택하는 과정을 단순화합니다. 사용자는 원하는 기능 및 작업에 적합한 모델을 쉽게 찾을 수 있습니다."]}],[{"l":"Overview"},{"l":"Moreh AI Model Hub Overview","p":["* Moreh AI Model Hub(MAMH) 작동 방식","Chatbot Comparison: 동일한 모델에 대한 파라미터 별 학습 시간 및 생성된 답변의 질을 비교하여 각 모델의 성능 차이를 비교할 수 있습니다.","Chatbot_Small, Chatbot_Medium, Chatbot_Large: 챗봇의 명칭은 사용된 언어 모델의 크기에 따라 구분되었습니다. 3개의 챗봇 모두 대형 언어 데이터를 기반으로 문맥을 이해하고 문장을 생성하며 다양한 주제에 대한 정보 제공, 질문 응답, 일상 대화를 통해 사용자와 상호작용합니다.","Code Generator: 사용자가 지정한 규칙 및 요구 사항에 따라, 프로그래밍 코드를 자동으로 생성하여 제공합니다.","Compare Model","Debugging: 입력한 함수를 디버깅 가능한 test case를 작성합니다.","Explain code: 사용자가 입력한 코드가 어떻게 작동하는지 설명합니다.","Generate code: 사용자가 작성한 주석을 수행하는 코드 작성합니다.","Image Generate AI","MAMH 의 목표는 AMD GPU만으로도 학습이 가능한 AI 모델을 사용하고 공유하는 과정을 단순화하고 개선하는 것입니다. 이 서비스는 다음 목적을 충족하기 위해 탄생하였습니다:","Moreh AI Model Hub 는 대규모 모델을 종합적으로 제공하는 서비스로, 언어뿐만 아니라 이미지 생성 및 모델 비교와 같은 다양한 작업을 수행합니다.","Moreh AI Model Hub(MAMH)는 무엇인가요?","Moreh AI Model Hub는 텍스트 및 이미지를 생성하고 언어를 번역하며 다양한 종류의 창의적인 콘텐츠를 작성하는 등의 작업을 하는 도구입니다.","Multi Modal AI","Random Image: 무작위로 선택된 이미지를 제공하는데, 일반적으로 사용자의 요청에 따라 랜덤하게 이미지를 생성합니다.","Text Generate AI","Text to Image Editing: 사용자가 입력한 텍스트 설명에 따라 이미지를 편집합니다.","Text to Image: 텍스트 입력을 기반으로 시각적 콘텐츠를 생성합니다.","Visual Question Answering: 이미지와 관련된 질문에 대답하는 기능을 제공합니다. 사용자가 이미지에 대한 질문을 하면, VQA는 이미지를 분석하고 자연어 처리 기술을 활용하여 해당 질문에 대한 응답을 생성하여 제공합니다.","공동 작업 및 공유: 모델 허브는 사용자 간에 AI 모델을 공동으로 작업하고 공유하는 데 편리한 방법을 제공합니다. 모델을 만들고 수정한 후 다른 사용자와 공유하거나 공동 작업할 수 있습니다. (To Be Determined)","모델 검색 및 선택의 용이성: Model Hub는 하드웨어 자원 및 시간 대비 학습 성능이 좋은 대규모 생성형 AI 모델을 검색하고 선택하는 과정을 단순화합니다. 사용자는 원하는 기능 및 작업에 적합한 모델을 쉽게 찾을 수 있습니다."]},{"i":"moreh-ai-model-hubmamh-사용-방법","l":"Moreh AI Model Hub(MAMH) 사용 방법","p":["좌측 Navigation바에서 MAMH에서 제공하는 모델중 하나를 선택합니다.","Text Generate AI","Chatbot_Small","Chatbot_Medium","Chatbot_Large","Code Generator","Image Generate AI","Text to Image","Random Image","Multi Modal AI","Text to Image Editing","Visual Question Answering","Compare Model","Chatbot Comparison"]}],[{"l":"Text Generate AI"},{"i":"chatbot-small-medium-large","l":"Chatbot (Small, Medium, Large)","p":["하단 Textbox에 프롬프트를 입력하면 MAMH가 학습한 정보를 사용하여 답변을 제공합니다.","다음은 한글/영어 특화 언어 모델을 사용한 Chatbot_Small, Chatbot_Medium, Chatbot_Large에서 시도해 볼 수 있는 몇 가지 프롬프트 예시 입니다.","(한글 프롬프트 예시)","“닭이 먼저야, 달걀이 먼저야?”","“특정 사회 문제를 다루는 비영리 단체를 위한 홍보 캠페인을 계획해줘.”","“단편 소설의 제목을 브레인스토밍하는 데 도움을 줘.”","(영문 프롬프트 예시)","Tell me the best places to travel on a budget of $1000 including car hire, flights and accommodation.","Write a summary of “The catcher in the rye”","Write me a step-by-step guide to use “AI Model Hub”","Generate a list of at least 10 keywords related to Mother nature"]},{"l":"Code Generator","p":["다음은 Code Generator에서 시도해 볼 수 있는 프롬프트 예시입니다.","(영문 프롬프트 예시)","Train a logistic regression model, predict the labels on the test set and compute the accuracy score","Continue writing this code in Python","Generate a function to find the value for (a+b)^3 using lambda.","Generate a Docker script to create a linux machine that has python 3.11.7 installed with following libraries: Pytorch, Tensorflow, Scikit- learn, pandas, numpy.","Generate a unit test for a function that determines if a year is a leap year or not.","(한글 프롬프트 예시)","lambda를 사용하여 (a+b)^ 3의 값을 찾는 함수를 작성해봐.","배열을 인수로 받아 가장 큰 값을 반환하는 함수(함수 이름: findMax) 를 작성해줘.","파이썬 3.11.7이 설치된 Linux 머신을 생성하기 위한 도커 스크립트를 짜줘."]}],[{"l":"Image Generate AI"},{"l":"Text to Image","p":["다음은 Text to Image 에서 시도해 볼 수 있는 프롬프트 예시입니다.","A creative composition of a frog wearing a crown sitting on a log","A 3D rendering of a chair that’s round and red","An illustration of a river winding through a meadow","A photograph of a person sitting on a bench facing the sunset in the style of Van Gogh","Untitled","Screenshot 2023-12-12 at 4.20.16 PM.png"]}],[{"l":"Multi Modal AI"},{"l":"Model Description"},{"i":"예시-chatbot_small","l":"예시: Chatbot_Small","p":["Modality(모델 타입): Text to Text","Training Resource(사용한 GPU 자원): AMD MI250 8 GPU","Training Time(학습 소요 시간)","Model Size: 30B - 35B"]}],[{"i":"privacy--terms","l":"Privacy & Terms"},{"l":"Moreh AI Model Hub 콘텐츠 사용 약관","p":["차별적이거나 공격적인 이미지를 생성하거나 업로드하지 마십시오.","악의적이고 공격적인 내용을 담은 콘텐츠","혐오를 조장하거나 부추기는 콘텐츠","폭력, 자해를 조장하는 내용을 담은 콘텐츠","개인을 조롱하거나 위협하거나 괴롭히는 내용을 담은 콘텐츠","특정 집단과 비교하거나 정체성을 기반으로 증오를 표현하거나 조장하는 콘텐츠","AI 생성물에 대해 현혹시키지 마십시오.","Model Hub에서 생성된 콘텐츠를 공유할 때 AI가 작업에 관여한 내용을 투명하게 공개하는 것이 좋습니다.","원하는 경우 Moreh hub 워터마크를 제거할 수 있지만 저작물의 성격에 대해 다른 사람을 오도해서는 안 됩니다. 예를 들어, 해당 작품이 전적으로 인간이 제작한 작품이거나 실제 사건을 그대로 촬영한 사진이라고 해서는 안 됩니다.","타인의 권리를 존중하세요.","동의 없이 타인의 이미지를 업로드하지 마세요.","적절한 사용 권한이 없는 이미지는 업로드하지 마세요.","서비스 이용 및 개인정보 사용 정책"]},{"l":"개인정보 처리 방침","p":["(주)모레 Moreh(이하 \"회사\"라 함)은 개인정보 보호법, 통신비밀보호법, 전기통신사업법, 정보통신망 이용촉진 및 정보보호 등에 관한 법률 등 정보통신서비스제공자가 준수하여야 할 관련 법령상의 개인정보보호 규정을 준수하며, 관련 법령에 의거한 개인정보 처리방침을 정하여 이용자 권익 보호에 최선을 다하고 있습니다."]},{"l":"1. 개인정보의 수집 및 이용목적","p":["개인정보는 생존하는 개인에 관한 정보로서 서비스 이용자를 식별할 수 있는 정보(당해 정보만으로는 특정 개인을 식별할 수 없더라도 다른 정보와 용이하게 결합하여 식별할 수 있는 것을 포함)를 말합니다. Moreh가 수집한 개인정보는 다음의 목적을 위하여 활용하고 있으며, 다음의 목적 이외의 용도로는 이용하지 않습니다.","Moreh Hub에서 이용자 간 주고받은 대화 기록: Moreh Hub에서 귀하가 입력한 내용을 처리하여 적절한 답변과 콘텐츠를 제공하고 이용자에게 맞춤화된 콘텐츠(메시지, 이미지, 오디오 등을 포함)를 제공하는 기본 기능을 제공하기 위해 개인정보를 활용합니다.","브라우징 환경을 모니터링하기 위한 쿠키 및 접속 로그","쿠키 사용을 허용하는 경우 사용자 개인 정보가 명시된 용도로 저장됩니다."]},{"l":"2. 개인정보 보유 및 이용기간","p":["이용자의 개인정보와 가명정보는 원칙적으로 개인정보와 가명정보의 수집 및 이용목적이 달성되면 지체 없이 파기합니다. 단, 다음의 정보에 대해서는 명시한 기간 동안 보존합니다.","방문에 관한 기록 및 쿠키","보존 이유 : 통신비밀보호법","보존 기간 : 3개월","Moreh Hub에서 이용자 간 주고받은 대화 기록","보존 이유: 사용자 경험 향상 및 서비스 성능 고도화 연구를 위한 한시적 보유","보존 기간: 연구 목적 달성 시까지"]}],[{"l":"AI Model Hub FAQ"},{"l":"FAQ","p":["Q. Moreh Hub는 내 개인 데이터를 어떻게 사용하나요?","Moreh Hub가 제공하는 대형 AI 모델은 공개적으로 사용 가능한 콘텐츠, 라이센스가 있는 콘텐츠, 검토자가 생성한 콘텐츠를 포함하는 광범위한 텍스트 및 이미지를 학습합니다. Moreh는 서비스 판매, 광고 또는 사람들의 프로필 등을 생성하기 위해 데이터를 사용하지 않습니다. Moreh Hub가 제공하는 모델의 답변의 질을 높이고 사람들에게 더 유용하게 만들기 위해서만 채팅 데이터를 사용합니다.","Q. Moreh Hub로 만들어진 이미지나 텍스트를 팔 수 있나요?","콘텐츠 사용 약관 과 개인정보 보유 및 이용기간 에 따라 Moreh Hub로 생성된 이미지는 사용자에게 해당 이미지를 재인쇄, 판매 및 상품화할 권리가 있습니다.","Q. Moreh Hub는 몇개의 언어를 지원하나요?","현재 Moreh Hub는 한국어, 영어 등의 언어로 제공됩니다. 사용자의 국가, 지역, 언어에 따라 일부 기능이 지원되지 않을 수 있으나 향후 기능 지원 범위를 넓혀 나갈 예정입니다.","Q. Moreh Hub를 사용할 때 어떤 서비스 약관이 적용되나요?","Moreh Hub의 AI 모델 사용시에는 Moreh AI Model Hub 콘텐츠 사용 약관이 적용됩니다.","Moreh AI Model Hub **** 서비스 관련 더 자세한 정보에 관한 질문이나 문의사항이 있으시면 contact@moreh.io 로 문의 부탁드립니다."]}],[{"l":"Getting Started"}],[{"l":"Overview"},{"l":"HAC Web Console 서비스 개요","p":["Admin User Manage","Cluster List","Global 모니터링","HAC Web Console Overview","HAC Web Console은 KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬에서 가장 적합한 사용자 경험을 제공합니다.","HAC Web Console을 사용하면 KTC 관리자는 다음과 같은 기능을 활용할 수 있습니다:","HAC 사용자 계정 관리","Home GPU 모니터링","Job & History","Notification Manage","SDA 모델 관리","Web Console Components","개발자의 니즈에 따라 GPU 자원 조정 가능: GPU 자원 분배에 관한 상태 값을 사용자의 편의와 요구에 따라 다양하게 조정할 수 있으며, 원활한 서비스 제공을 위해 필요한 조치를 즉시 취할 수 있습니다.","실시간 GPU 상태 모니터링: 서버 상태와 노드별 동작 여부를 확인하고, GPU의 가용성 및 예약 현황을 실시간으로 쉽게 파악할 수 있습니다. 또한, GPU 관련 작업 로그를 통해 성능 이슈나 문제를 신속하게 분석할 수 있습니다.","위 제공된 기능들을 통해 KT Cloud 관리자는 GPU 리소스를 효율적으로 관리하고, 클러스터의 안정성을 바탕으로 사용자들에게 원활한 서비스를 제공할 수 있습니다.","클러스터 설정"]}],[{"i":"#","p":["이 문서는 HAC Web Console로 GPU 자원 모니터링 및 관련 작업 등을 위한 가이드입니다. KTC 관리자가 HAC 클러스터의 자원 사용을 최적화하고 발생 가능한 문제를 빠르게 대응하는데 도움을 줍니다."]},{"l":"Web Console Components","p":["Cluster List","Admin User Manage","Notification Manage","Home GPU 모니터링","Global 모니터링","Job & History","HAC 사용자 계정 관리","SDA 모델 관리","클러스터 설정"]},{"l":"1. HAC Web Console 개요","p":["HAC Web Console은 KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","HAC Web Console을 사용하면 KTC 관리자는 다음과 같은 기능을 활용할 수 있습니다:","실시간 GPU 상태 모니터링: 서버 상태와 노드별 동작 여부를 확인하고, GPU의 가용성 및 예약 현황을 실시간으로 쉽게 파악할 수 있습니다. 또한, GPU 관련 작업 로그를 통해 성능 이슈나 문제를 신속하게 분석할 수 있습니다.","개발자의 니즈에 따라 GPU 자원 조정 가능: GPU 자원 분배에 관한 상태 값을 사용자의 편의와 요구에 따라 다양하게 조정할 수 있으며, 원활한 서비스 제공을 위해 필요한 조치를 즉시 취할 수 있습니다.","위 제공된 기능들을 통해 KT Cloud 관리자는 GPU 리소스를 효율적으로 관리하고, 클러스터의 안정성을 바탕으로 사용자들에게 원활한 서비스를 제공할 수 있습니다.","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬에서 가장 적합한 사용자 경험을 제공합니다."]},{"l":"2. Web Console Components","p":["Admin User Manage (관리자 정보 변경 및 권한 설정하기)","Cluster List","Global 모니터링","GPU 클러스터의 상태 및 실시간 사용 정보를 지표로 나타냅니다.","HAC GPU 사용을 위한 전용 관리 페이지입니다.","HAC 사용자 관리","Home GPU 모니터링","Job & History","Notification Manage (전체 알림 관리하기)","SDA 모델 관리","Web Console의 요소들과 각 기능을 어떻게 사용할 수 있는지 설명합니다.","각 클러스터 당 모레 솔루션의 버전을 관리할 수 있습니다.","각 클러스터에 포함된 모든 HAC 사용자 정보(사용자 그룹 수, 누적 사용량, 전체 SDA 개수 등)를 제공합니다.","각 클러스터에서 HAC 사용자에게 제공되는 SDA Model을 관리할 수 있습니다.","각각의 클러스터에 포함된 GPU 자원의 종합적인 모니터링이 가능하며 HAC 사용자에게 제공되는 GPU를 관리할 수 있습니다.","어떤 페이지에서든 빠르게 전체 GPU 클러스터에 포함된 GPU Node 들의 상태를 모니터링할 수 있습니다.","클러스터 내 GPU를 사용하는 작업을 관리하고 작업 진행 상황과 작업에 관련된 로그 및 세부사항을 확인할 수 있습니다.","클러스터 설정"]},{"l":"1. Cluster List","p":["✔️Master 권한의 관리자만 새로운 Admin 계정을 추가할 수 있습니다.","Admin User List 상단의 [+ Add] 버튼을 클릭하면 Modify Personal Info(Admin 개인 정보 수정) 모달과 동일한 모달이 아래와 같이 등장합니다. 모달에 추가할 관리자 정보를 입력합니다.","Admin User List에서 특정 관리자의 첫번째 Interaction 아이콘을 클릭하면 관리자에 대한 정보를 수정할 수 있습니다. Master 계정의 사용자는 계정(General, Master 모두)에 대한 정보를 수정 가능 하며, General 계정의 사용자는 개인 계정 정보만 수정 가능합니다.","Admin User Manage (관리자 개인 정보 변경 및 권한 설정하기)","Admin 관리자 계정 추가하기","Cluster List 는 HAC Web Console의 모든 클러스터에 대한 통합 개요 정보와 특정 클러스터의 세부 정보(패키지 배포 서버 상태, SDA Manager 상태, GPU의 클러스터 사용률 등)를 제공합니다.","Cluster 이름, IP 주소는 필수 입력 항목입니다.","Cluster 추가하기","General 계정 : 개인 계정 정보만 수정 가능","GPU 디바이스 온도가 86~ 93°C인 경우 주의 단계 알림","GPU 디바이스 온도가 94~ 97°C인 경우 경고 단계 알림","GPU 디바이스 온도가 98~°C인 경우 조치 단계 알림","GPU 부족","GPU 에러","GPU 온도","Master 계정 : Moreh에서 직접 만들어서 제공하는 계정이며 General, Master 계정 모두 생성과 수정 가능","Master 권한, General 중 선택합니다.","Notification Manage (전체 알림 관리하기)","Notification Manage 페이지의 Notification List(클러스터 알람 목록)에 [+ Add Filter] 버튼을 클릭하면 다음 필터 패널이 나타납니다. 알림 특정 태그를 추가/제외 가능합니다.","Untitled","개별 클러스터 삭제 시 확인 모달에서 [삭제] 버튼 클릭","관리자 ID","관리자 권한","관리자 이름 (필수 입력 사항)","권장사이즈: 120px(width) * 120px(height) 또는 1:1 비율","두번째 Interaction 아이콘을 클릭하면 해당 관리자의 권한을 General/Master로 변경할 수 있습니다. ✔️Master 권한의 관리자만 변경 가능합니다.","로그인 인증 정보로 로그인하여 HAC 웹콘솔에 접속하면 첫 페이지가 다음과 같이 표시됩니다.","메일 주소이며 한 번 생성된 후에는 변경 불가능합니다.","모니터링할 특정 기간에 대해 년, 월, 일 시간으로 시작 날짜와 종료 날짜를 입력합니다.","물리 GPU에 에러가 발생한 경우","비밀번호 (필수 입력 사항)","사용자 관리 페이지에서 왼쪽 사이드바의 [Permission Manage]를 클릭하면 아래와 같이 Admin User List가 나타납니다. Admin User List에는 사용자 프로필 아이콘, 관리자 ID, 관리자 이름, 권한 Type 정보와 Master 권한의 관리자가 상호작용가능한 아이콘이 제공됩니다.","상단 우측의 [Notification Manage] 버튼 과 [Admin User Manage] 버튼 을 클릭한 후 각 알람 관리 페이지와 Admin 사용자 관리 페이지로 이동하여 Admin 사용자 개인정보와 권한 및 웹콘솔의 모든 알림과 Admin 사용자를 관리할 수 있습니다.","선택 사항이며 미입력시 디폴트 아이콘이 제공됩니다.","세번째 휴지통 모양의 Interaction 아이콘을 클릭하면 해당 관리자를 삭제할 수 있습니다. ✔️Master 권한의 관리자만 삭제 가능합니다.","아래 모달 창이 뜨면 추가할 클러스터 정보(이름, IP 주소, Description)를 입력합니다.","아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","알림리스트 중 모니터링할 클러스터를 선택 가능합니다.","영문, 숫자 또는 대문자 포함 제한이 없습니다.","웹 콘솔의 첫 화면에서 아래 클러스터 추가 [+ ADD Cluster] 아이콘을 클릭합니다.","이 페이지에서 클러스터의 개요 정보를 확인하고, 클러스터 목록을 통해 개별 클러스터로 진입할 수 있습니다. 또한 관리자 계정의 개인정보와 권한을 설정할 수 있습니다.","작업 에러","제공되는 알림 분류 중 선택 가능합니다.","진행 중이던 작업이 에러가 발생하여 멈춘 경우","클러스터에 배정된 GPU 자원이 부족하여 대기열 속 다음 작업을 진행하지 못하는 경우","프로필 사진"]},{"l":"2. Home GPU Monitoring","p":["(예시) Group A 클러스터에 등록된 A100, V100, MI250 세 종류가 있을 경우 GPU 디바이스 종류의 개수: 3개 로 표현","00~05 로 그룹핑되어있는 부분이 같은 사용자가 사용하는 노드입니다. 그룹핑된 부분에 마우스 오버시 해당 디바이스 묶음을 사용하는 토큰에 대한 정보가 툴팁으로 제공됩니다.","00번 부터 07번까지 각 GPU 디바이스로 구분","Add Filter를 적용할 경우 선택된 필터링 내용을 해시태그 형태로 제공합니다.","CPU 온도와 노드 메모리 사용률 정보","Description (Cluster 추가 시 Admin 관리자가 입력한 노드 사용 관련 내용 )","GPU 디바이스 종류의 개수","GPU 디바이스의 사용 현황이 색상으로 표현됨","GPU 메모리 정보","GPU 정보","GPU 종류","GPU 현재 상태를 다음 3가지로 구분하여 선택된 상태에 해당하는 노드가 필터링 결과로 제공됩니다.","Grid(바둑판 뷰)의 노드 1개의 이미지","HAC Web Console 효율성 (Service Efficiency)","Node - Grid 에서 노드 1개의 정보는 아래와 같이 나타납니다.","Node Group","Node Group List 우측 상단에 [+ Add] 버튼을 클릭한 후 아래 모달에서 필요한 정보를 입력합니다.","Node Group 이름","Node Group은 다음 정보를 제공합니다.","Node List 에서 모니터링 리스트에서 제공하는 노드 정보는 위 Node - Grid(바둑판 뷰)의 셀과 동일합니다.","Node Monitor","Node 개수와 GPU 자원의 양으로 나타냄","Overview 클러스터 개요","Screen Shot 2023-07-30 at 4.19.00 PM.png","SDA Manager 상태 (원활/불량)","Untitled","User","그룹에 대한 설명","노드 그룹","노드 그룹 이름 (필수 입력 사항)","노드 그룹 추가하기","노드 목록에 필터링 적용하기","노드 이름 (호스트 이름)","노드가 소속된 GPU 디바이스 그룹","대기중 (Idle)","리스트 우측 상단에 다음 [+ Add Filter] 버튼을 클릭하여 아래 모달에 노드 목록에 표시될 항목을 선택합니다.","링크 클릭시 HAC 사용자 관리 페이지로 이동합니다.","모니터링 리스트는 Grid(바둑판 뷰)와 List(목록형 뷰)로 제공되며 사용중인 노드와 이름 순서로 정렬됩니다.","빨간색 - 사용 불가 (Shutdown)","사용 가능한 노드 개수","사용 불가 (Shutdown)","사용중 (Processing)","사용중인 Node 개수와 GPU 자원의 양을 전체 대비 백분율로 나타냄","삭제","상호작용","선택된 노드리스트","설명","수정","연관된 SDA 모델 그룹","전일 기준으로 1주일 동안 평균 사용한 노드 수와 GPU 디바이스 수 (전체 대비 백분율)","전체 노드 그룹, Group A, Group B, Group C에 해당하는 노드가 필터링 결과로 제공됩니다.","전체 노드 중 사용 불가능한 노드와 GPU 자원의 양을 전체 대비 백분율로 나타냄","전체 사용자 계정이 선택한 SDA Model의 GPU 자원의 총합 / 평균 사용중인 GPU 자원의 양 = %","전체 사용자 계정이 제공되며 특정 계정을 추가하거나 제외할 수 있습니다.","초록 - 사용중 (Processing)","최상단 디바이스 번호에 토큰 포함관계가 표현","클러스터에 포함된 전체 노드 리스트와 선택된 노드 리스트가 제공되며 검색, 체크박스 선택 등을 통해서 상호작용이 가능합니다.","특정 노드 이름 혹은 그룹이름에 대해 검색창에 찾아볼 수 있습니다.","패키지 배포 서버 상태 (원활/불량)","평균 사용 중인 노드 수","포함된 노드 개수","포함된 디바이스 종류","해당 디바이스 메모리의 현재 온도와 사용률을 나타냄","해당 클러스터를 사용중인 HAC 사용자 계정 개수","해당 클러스터에 포함되어 있는 전체 노드 수","현재 클러스터에서 사용 불가능한 노드 수","현재 클러스터에서 사용 중인 노드 수","현재 해당 클러스터에 등록된 물리적인 GPU 제품 종류의 개수","현재 해당 클러스터에 존재하는 사용자가 설정한 GPU 종류에 따라 필터링 가능하며 체크 박스 형태로 여러개 선택 가능합니다.","호함된 노드 수","회색 - 대기중 (Idle)"]},{"l":"3. Global 모니터링","p":["Global Monitoring 페이지는 사용자가 HAC Web Console 내부에서 전체 클러스터를 빠르게 시각적으로 모니터링할 수 있도록 도와주는 패널입니다. 로컬 화면의 좌측 Navigation 바 하단에 위치한 글로벌 모니터링 아이콘을 클릭하면 다음 페이지가 나타납니다.","Global Monitoring 페이지의 전체 클러스터 개요와 각 클러스터는 다음과 같은 정보를 포함합니다.","Overview - All Clusters (클러스터 개별 개요)","SDA Manager서버","Untitled","노드들 중 간혹 두 명 이상의 HAC 사용자가 하나의 노드를 나누어서 사용하는 경우가 있습니다.","따라서 하나의 노드를 두 명 이상의 HAC 사용자가 사용하는 경우에는 해당 노드에 마우스 오버 시 아래 툴팁 이미지와 같이 사용중인 노드 이름과 현재 상태(Processing/Idle/Shutdown), 사용시간, GPU index 번호, 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 나타납니다.","빨강 Shutdown - 해당 노드를 사용했던 사용자 계정 정보와 셧다운된 시각","사용 가능한 노드 수","사용 불가능한 노드 수","사용중인 노드 수","서비스 효율성","이런 경우 노드에 마우스 오버 시 나오는 정보 툴팁도 해당 노드를 사용하는 HAC 사용자가 한명일 때와 여러 명일 때가 구분됩니다. 예를 들어 3개의 노드와 4개의 GPU를 사용하는 경우 해당 HAC 사용자가 사용하는 3개의 노드에 마우스 오버하면 한 명의 유저에 대한 툴팁만 나오겠지만, 4번째 노드인 GPU 4개를 사용하는 노드에 마우스를 오버하면 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 툴팁에 제공됩니다. 또한 툴팁에 제공되는 모든 엔드유저가 사용 중인 노드 시각화 또한 하이라이트 됩니다.","전체 노드 수","초록 Processing - 해당 노드를 사용하는 사용자 계정 정보와 사용시간","클러스터 모니터링","클러스터의 각 노드에 마우스 오버시 현상태에 따라 아래 정보가 제공됩니다.","패키지 배포 서버","평균 사용 노드 수","하나의 노드를 여러명의 HAC 사용자 사용했을때 툴팁","하나의 노드를 한명의 HAC 사용자 사용했을때 툴팁","회색 Idle - 해당 노드가 포함된 GPU 그룹 정보"]},{"i":"4-job--history","l":"4. Job & History","p":["Framework (사용 프레임워크 버전)","GPUs (SDA Model 이 사용중인 GPU 개수)","History List (작업 히스토리)","History List에는 가장 최근에 종료된 작업순으로 정렬됩니다.","Id (아이디)","Interaction (상호작용 아이콘 - 우선순위 변경하기, 특정 작업 취소하기)","Job List (작업목록)","Job Priority (작업 우선순위)","Job 목록에 사용자가 요청한 작업은 사용자의 우선순위에 해당되는 기본값을 가지고 들어오며, 만약 작업이 대기열에 들어가게 되면 해당 우선순위 값을 첫 번째 정렬 값으로 사용하여 대기열에 적용됩니다. 이렇게 정렬된 대기열(Queue)에 있는 각 작업의 우선순위를 수동으로 변경할 수 있습니다.","MAF ver (모레 솔루션 버전)","Overview (작업 개요)","Queued-> 클러스터에 해당 작업에 필요한 GPU가 부족하여 진행중이지 못한 작업","Request Time (작업 요청된 시간)","Running -> 현재 진행중인 작업으로 GPU 사용중","Running Time (진행 시간)","Start Time (시작 시간)","Status (현재 상태)","Untitled","Untitled-8.png","User (사용자)","Waiting Time (대기중인 시간)","개별 Job 항목을 클릭하면 확인할 수 있는 작업 로그","개별 클러스터에서 GPU를 사용하여 해당 클러스터에서 진행중인 작업(Job)과 작업 히스토리를 확인하고 GPU 배정이 필요한 작업 간의 우선 순위를 조정하여 먼저 할당 받을 수 있는 페이지입니다. 작업 목록에서 개별 작업 항목을 클릭하면 세부 로그를 확인할 수 있는 페이지로 이동합니다.","리스트에서 각 작업의 우선순위 변경 아이콘을 클릭하면 모달을 통해 작업 우선순위 변경이 가능합니다.","사용자 Job 대기열 우선순위 설정하기","사용자 계정 별로 기본 우선순위가 있으며 Queue에서 우선순위가 가장 높은 Job이 먼저 GPU 노드를 할당 받을 수 있습니다.","시,분, 일 변화 단위로 따라가기 (사용한지 25시간 -> 1D 1H 로 표기)","우선순위 값(-99~ 99 사이의 정수)이 99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당 됩니다.","작업 목록에는 다음 정보가 표시됩니다.","작업 우선순위(Priority)","작업 우선순위는 Job Queue에서 대기중인 Job중에서 할당받는 순서를 결정합니다.","전체 노드 혹은 노드 별로 확인이 가능합니다.","전체적으로 작업 목록(Job List)와 동일한 값을 제공하며 상태값(Status)만 Completed(완료), Expired(HAC사용자 또는 Admin의 input 없이 모종의 에러로 종료), Canceled(HAC 사용자가 수동으로 종료) 로 제공됩니다.","해당 작업이 가지는 고유 ID 정보","현재 사용 가능한 디바이스와 에러가 발생한 작업수 등을 표시됩니다."]},{"i":"5-end-userhac-사용자-관리하기","l":"5. End User(HAC 사용자) 관리하기","p":["-99~ 99 사이의 숫자로 설정","-99~ 99사이의 숫자 (default=0)","(default = not selected)","99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당됩니다.","Admin 사용자가 지정한 HAC 사용자 그룹","default value = 0","default value = 1","GPU 사용 안하는중","GPU 사용중","GPU 작업 대기중","HAC 사용자 SDA 번호","HAC 사용자 정보 삭제하기","HAC 사용자 추가하기","HAC 사용자에게 제공되는 SDA의 고유 ID","HAC 사용자에게 허용되는 SDA 개수","Key-Value 쌍으로 입력합니다.","Max Multi Use: 1개의 SDA로 n 번 GPU를 할당할 때 n 의 최대값","MAX SDA","Max SDA = 1 인 경우 Max Multi Use 활성화","Max SDA = 1 인 경우에만 사용 가능합니다.","Max SDA 1 인 경우 Max Multi Use 비활성화","MAX SDA 수","Max SDA 수 (필수 입력사항)","Overview (전체 유저 개요 정보)","SDA Model * N","SDA 추가하기","Untitled","User List (사용중 - 대기중 순서로 정렬)","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 정보를 수정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 환경변수를 설정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 Key 와 Value 값을 입력합니다.","User List에 새로운 HAC 사용자를 추가하려면 우측 상단에 **[+ Add User]** 버튼을 클릭 후 아래 모달에서 다음 정보를 입력합니다.","User Manage 페이지에서는 사용자 관리 페이지에서는 해당 클러스터에 포함된 모든 HAC 사용자를 관리할 수 있습니다. 상단에 있는 전체 유저 개요 정보와 하단의 User List(사용자 목록)이 제공됩니다.","User Name","값이 1이 아닌경우 해당 MAX SDA 값만 제공됩니다.","값이 1인 경우 허용된 Multi Use 값이 제공됩니다.","누적 사용량 (Total Usage)","사용자 계정 정보 변경하기","사용자 그룹 설정하기","사용자 그룹 수","사용자 삭제","사용자 우선순위","사용자 이름 (User)","사용자 이름 (필수 입력 사항)","사용자 정보 변경시 아래 정보를 입력합니다.","사용자 정보 편집","사용자 환경변수 설정","사용자 환경변수 설정하기","사용자가 작업을 시작하면 해당 작업에 우선순위가 부여되며, 이 우선순위는 작업 목록에서 사용자 우선순위와 별개로 조정할 수 있습니다. (기본 값 = 0)","사용중인 SDA Model","상호작용 아이콘","소속 그룹 (User Group)","여러 Key-Value 쌍을 추가할 수 있으며 한 번 입력한 환경변수를 삭제할 수 있습니다.","우선 순위 (Priority)","작업 우선순위는 기본 값(0)과 작업 목록에서 조정 가능한 값으로 구분됩니다.","전체 SDA 수","전체 유저 수","좌측 휴지통 모양 아이콘을 클릭해서 사용자 정보를 삭제할 수 있으며 삭제 후에는 기본 정보를 불러올 수 없습니다.","총 누적 사용량 (GPU를 사용한 시간)","최근 실행 시간 (Recent Use)","하단의 SDA Model 선택은 한 개만 가능하고 추가 버튼 비활성화","하단의 드롭다운 버튼을 클릭해서 max SDA에서 설정한 N개의 SDA Model 추가 가능","현재 상태"]}],[{"l":"Platform Cloud Service"},{"l":"Platform Cloud Service 란","p":["Platform Cloud Service(PCS)는 컨테이너화된 애플리케이션을 배포하고 관리하기 위한 확장성이 뛰어난 클라우드 기반 인프라 서비스입니다. Kubernetes라는 오픈소스 컨테이너 플랫폼을 기반으로 하며, 컨테이너화된 애플리케이션을 관리하기 위한 다양한 기능을 제공합니다.","클러스터 관리: Kubernetes 클러스터를 손쉽게 관리할 수 있도록 하며, 필요에 따라 클러스터의 크기를 조정할 수 있습니다.","컨테이너 배포 및 관리: Docker 및 기타 인기 있는 컨테이너 형식을 지원하여 컨테이너를 배포하고 관리할 수 있습니다.","네트워킹 및 스토리지: 로드 밸런싱 및 영구 스토리지와 같은 네트워킹 및 스토리지 옵션을 제공합니다.","모니터링 및 로깅: Prometheus 및 Grafana와 같은 모니터링 및 로깅 툴을 제공합니다."]}]]